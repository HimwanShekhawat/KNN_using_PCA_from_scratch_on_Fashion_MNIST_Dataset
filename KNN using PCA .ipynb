{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the Fashion MNIST dataset (CSV format)\n",
    "df = pd.read_csv(\"/kaggle/input/fashion-mnist-train-csv/fashion-mnist_train.csv\")\n",
    "\n",
    "# Group data by label to stratify manually\n",
    "grouped = df.groupby(\"label\")\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# Split each class into 80% train and 20% test\n",
    "for label, group in grouped:\n",
    "    train_split, test_split = train_test_split(\n",
    "        group,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "        stratify=None  # Manual stratification\n",
    "    )\n",
    "    train_list.append(train_split)\n",
    "    test_list.append(test_split)\n",
    "\n",
    "# Combine splits and shuffle\n",
    "train_df = pd.concat(train_list).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Show one example image per class\n",
    "examples = train_df.groupby(\"label\").first().reset_index()\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    img = examples.loc[i].drop(\"label\").values.astype(np.uint8).reshape(28, 28)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"Label: {examples.loc[i, 'label']}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract feature matrix and labels\n",
    "X = train_df.drop(\"label\", axis=1).values.astype(np.float32)\n",
    "y = train_df[\"label\"].values\n",
    "\n",
    "# Center the data by subtracting mean\n",
    "x_mean = np.mean(X, axis=0)\n",
    "X = X - x_mean\n",
    "\n",
    "# Compute covariance matrix\n",
    "covar_x = (1 / (X.shape[0] - 1)) * (X.T @ X)\n",
    "\n",
    "# Eigen decomposition\n",
    "eigen_values, eigen_vector = np.linalg.eig(covar_x)\n",
    "\n",
    "# Sort eigenvalues and eigenvectors in descending order\n",
    "sort_idx = np.argsort(eigen_values)[::-1]\n",
    "sort_vect = eigen_vector[:, sort_idx]\n",
    "eigen_values = eigen_values[sort_idx]\n",
    "\n",
    "# Select top k principal components\n",
    "k = 64\n",
    "W = eigen_vector[:, :k]\n",
    "\n",
    "# Project data onto reduced space\n",
    "X_red = X @ W\n",
    "\n",
    "# k-Nearest Neighbors prediction\n",
    "k_neighbors = 5\n",
    "y_pred = []\n",
    "\n",
    "for i in range(1000):  # Predict labels for first 1000 samples\n",
    "    # Compute distances to all others\n",
    "    all_dist = np.full(1000, np.inf)\n",
    "    for j in range(1000):\n",
    "        if i != j:\n",
    "            all_dist[j] = np.linalg.norm(X_red[i] - X_red[j])\n",
    "\n",
    "    # Find k nearest neighbors\n",
    "    min_x = np.argsort(all_dist)[:k_neighbors]\n",
    "\n",
    "    # Get labels and vote\n",
    "    y_all = y[min_x]\n",
    "    counts = np.bincount(y_all)\n",
    "    y_pred.append(np.argmax(counts))\n",
    "\n",
    "# Compute classification accuracy\n",
    "acc = np.mean(y_pred == y[:1000]) * 100\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
